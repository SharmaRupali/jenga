{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5J3YuFydIxdZ"
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Ag3FZmFIxdb"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from jenga.basis import Dataset\n",
    "from jenga.models.model import Model\n",
    "from jenga.corruptions.perturbations import Perturbation\n",
    "from jenga.cleaning.imputation import MeanModeImputation, DatawigImputation\n",
    "from jenga.cleaning.outlier_detection import PyODKNN, PyODIsolationForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a-iy_7t6Ixdq"
   },
   "outputs": [],
   "source": [
    "seed = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "shQyScYzIxd3",
    "outputId": "6a663f31-520c-4577-b869-7e37216eb49c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = Dataset(seed, \"credit-g\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "btvkVjkhIxeB",
    "outputId": "fc022378-c139-40a5-ae52-71e0c014c320",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_data = dataset.all_data\n",
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_fXEYeDDIxeJ",
    "outputId": "fb00199f-0389-432e-f03c-727f6a8c6571",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "attribute_names = dataset.attribute_names\n",
    "attribute_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FSY8TywSIxeR",
    "outputId": "85db3b5a-8229-4db2-9f88-937e4c598590",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "attribute_types = dataset.attribute_types\n",
    "attribute_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5uMuqQUlIxea",
    "outputId": "fc695e35-b09f-41de-d929-c96847938c52"
   },
   "outputs": [],
   "source": [
    "categorical_columns = dataset.categorical_columns\n",
    "categorical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZjJYdTMkIxeg",
    "outputId": "1621cccd-7299-4cf4-b279-7fb7459fef45",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "numerical_columns = dataset.numerical_columns\n",
    "numerical_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zAftqPZ3Ixel"
   },
   "source": [
    "### Visualize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ngMsX7a_Ixem"
   },
   "outputs": [],
   "source": [
    "## plot the original dataset\n",
    "def hide_current_axis(*args, **kwds):\n",
    "        plt.gca().set_visible(False)\n",
    "        \n",
    "def plot_data(data):\n",
    "    sns.set_style(\"white\") # grid/no grid style: darkgrid, whitegrid, dark, white, ticks\n",
    "    \n",
    "    plot = sns.pairplot(data, hue=\"class\")\n",
    "    plot.map_upper(hide_current_axis)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gvPzUqAgIxev"
   },
   "outputs": [],
   "source": [
    "plot_data(all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8svnusk-Ixe2"
   },
   "source": [
    "### Get training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "773WHs-7Ixe3",
    "outputId": "d1f2cb8d-89e0-4633-dea4-fa415f74b3eb",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data, train_labels, test_data, test_labels = dataset.get_train_test_data()\n",
    "\n",
    "display(train_data.head())\n",
    "print(train_labels[0:5])\n",
    "\n",
    "display(test_data.head())\n",
    "print(test_labels[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LlqGYzOaIxe_"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zeChOIyIIxfA"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "# model parameters\n",
    "learner = SGDClassifier(max_iter=1000)\n",
    "param_grid = {\n",
    "    'learner__loss': ['log'],\n",
    "    'learner__penalty': ['l2', 'l1', 'elasticnet'],\n",
    "    'learner__alpha': [0.0001, 0.001, 0.01, 0.1]\n",
    "}\n",
    "\n",
    "\n",
    "# preprocessing pipeline for numerical columns\n",
    "transformer_numeric = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value=0)),\n",
    "    ('standard_scale', StandardScaler())\n",
    "])\n",
    "\n",
    "# preprocessing pipeline for categorical columns\n",
    "transformer_categorical = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='__NA__')),\n",
    "    ('one_hot_encode', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# preprocessor\n",
    "feature_transform = ColumnTransformer(transformers=[\n",
    "    ('categorical_features', transformer_categorical, categorical_columns),\n",
    "    ('numerical_features', transformer_numeric, numerical_columms)\n",
    "])\n",
    "\n",
    "## prediction pipeline: append classifier (learner) to the preprocessing pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('features', feature_transform),\n",
    "    ('learner', learner)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LtrcJi_0IxfJ"
   },
   "outputs": [],
   "source": [
    "model_obj = Model(seed, train_data, train_labels, test_data, test_labels, categorical_columns, numerical_columms, pipeline, learner, param_grid)\n",
    "\n",
    "model = model_obj.fit_model(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f7JbgMFdIxfQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MrHxvFFkIxfX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LcrP1MEBIxfd"
   },
   "source": [
    "## Corruptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5SIdfgEhIxfe"
   },
   "outputs": [],
   "source": [
    "# corruption perturbations to apply\n",
    "corr_perturbations = Perturbation(categorical_columns, numerical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RGtVQXRcIxfj",
    "outputId": "dab2c6ad-998c-4094-ba27-ede1889b49d9",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_data_corrupted, perturbations, cols_perturbed = corr_perturbations.apply_perturbation(test_data, 5)\n",
    "test_data_corrupted.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f5PwmWwhIxfo",
    "outputId": "0d28422d-b7c5-47a6-eeea-6f7318f129ff"
   },
   "outputs": [],
   "source": [
    "perturbations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BSTWKTXYIxfu",
    "outputId": "7c948813-c694-415a-a749-c4879b089b1d"
   },
   "outputs": [],
   "source": [
    "cols_perturbed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gLZUJSdkIxf0"
   },
   "source": [
    "### Visualize the original and corrupted test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hCepLGGDIxf1"
   },
   "outputs": [],
   "source": [
    "## original test data\n",
    "plot_data(pd.concat([test_data, pd.Series(test_labels, name='class')], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TDy7xiLeIxf8"
   },
   "outputs": [],
   "source": [
    "## corrupted test data\n",
    "plot_data(pd.concat([test_data_corrupted, pd.Series(test_labels, name='class')], axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AjsysJeNIxgD"
   },
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a60vmKbOIxgE"
   },
   "source": [
    "### Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t3_u36jiIxgG",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mean_mode_imputer = MeanModeImputation(train_data, test_data_corrupted, categorical_columns, numerical_columns)\n",
    "\n",
    "test_data_mm_imputed = mean_mode_imputer.fit_transform(train_data, test_data_corrupted)\n",
    "test_data_mm_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6DcKFbr2IxgY"
   },
   "outputs": [],
   "source": [
    "datawig_imputer = DatawigImputation(train_data, test_data_corrupted, categorical_columns, numerical_columms)\n",
    "\n",
    "test_data_dw_imputed = datawig_imputer.fit_transform(train_data, test_data_corrupted)\n",
    "test_data_dw_imputed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MmGlCZSmIxge"
   },
   "source": [
    "##### Using PPP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PQ1ZGFjLIxgf"
   },
   "outputs": [],
   "source": [
    "# for all imputers return scores, take best\n",
    "# using ppp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GbwAr7RIIxgi"
   },
   "outputs": [],
   "source": [
    "from jenga.cleaning.imputation import MeanModeImputation, DatawigImputation\n",
    "from jenga.cleaning.ppp import PipelinePerformancePrediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m85gO-9wIxgp"
   },
   "outputs": [],
   "source": [
    "learner = SGDClassifier(max_iter=1000)\n",
    "param_grid = {\n",
    "    'learner__loss': ['log'],\n",
    "    'learner__penalty': ['l2', 'l1', 'elasticnet'],\n",
    "    'learner__alpha': [0.0001, 0.001, 0.01, 0.1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "--5LXVPBIxgs"
   },
   "outputs": [],
   "source": [
    "ppp = PipelinePerformancePrediction(seed, train_data, train_labels, test_data, test_labels, categorical_columns, numerical_columns, learner, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q2dm7M3NIxgy"
   },
   "outputs": [],
   "source": [
    "# generate corrpted test data\n",
    "test_data_corrupted, perturbations, cols_perturbed = ppp.get_corrupted(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TNXavjuTIxg3"
   },
   "outputs": [],
   "source": [
    "imputer_candidates = [MeanModeImputation, DatawigImputation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "06A5iTlUIxg8"
   },
   "outputs": [],
   "source": [
    "imputers = []\n",
    "for imputer in imputer_candidates:\n",
    "    imputers.append(imputer(train_data, test_data_corrupted, categorical_columns, numerical_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oY0vQKE8IxhA"
   },
   "outputs": [],
   "source": [
    "imputers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7UyZby9SIxhC"
   },
   "outputs": [],
   "source": [
    "ppp_model = ppp.fit_ppp(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pZJ7YjjfIxhH"
   },
   "outputs": [],
   "source": [
    "score_no_cleaning = ppp.predict_score_ppp(ppp_model, test_data)\n",
    "score_no_cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V5g7ZToxIxhK",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imputed_scores_ppp = []\n",
    "for imputer in imputers:\n",
    "    test_data_imputed = imputer.fit_transform(train_data, test_data_corrupted)\n",
    "    imputed_score = ppp.predict_score_ppp(ppp_model, test_data_imputed)\n",
    "    print(f\"PPP score with {imputer}: {imputed_score}\")\n",
    "    imputed_scores_ppp.append(imputed_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7SHiTdg2IxhQ"
   },
   "outputs": [],
   "source": [
    "imputed_scores_ppp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "96skIfBSIxhS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0P4waPRvIxhU"
   },
   "source": [
    "##### Using PPP and Cleaner classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "59bCPn_GIxhW"
   },
   "outputs": [],
   "source": [
    "from jenga.cleaning.ppp import PipelinePerformancePrediction\n",
    "from jenga.cleaning.cleaner import Cleaner\n",
    "from jenga.cleaning.outlier_detection import NoOutlierDetection, PyODKNN, PyODIsolationForest\n",
    "from jenga.cleaning.imputation import NoImputation, MeanModeImputation, DatawigImputation\n",
    "from jenga.cleaning.clean import Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FSVCF_JIIxhd"
   },
   "outputs": [],
   "source": [
    "learner = SGDClassifier(max_iter=1000)\n",
    "param_grid = {\n",
    "    'learner__loss': ['log'],\n",
    "    'learner__penalty': ['l2', 'l1', 'elasticnet'],\n",
    "    'learner__alpha': [0.0001, 0.001, 0.01, 0.1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3Nm8W449Ixhh"
   },
   "outputs": [],
   "source": [
    "ppp = PipelinePerformancePrediction(seed, train_data, train_labels, test_data, test_labels, categorical_columns, numerical_columns, learner, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rxxY7KqbIxhk",
    "outputId": "6b7fbfe9-ef4a-4e7e-ca16-28110c590be6",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ppp_model = ppp.fit_ppp(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OSrYKsdhIxhp",
    "outputId": "e1a2d958-5765-4b48-a34a-504848d36b43"
   },
   "outputs": [],
   "source": [
    "ppp_model_score = ppp.predict_score_ppp(ppp_model, test_data)\n",
    "ppp_model_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate corrpted test data\n",
    "test_data_corrupted, perturbations, cols_perturbed = ppp.get_corrupted(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_no_cleaning = ppp.predict_score_ppp(ppp_model, test_data_corrupted)\n",
    "score_no_cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kn-xq4CWIxhY"
   },
   "outputs": [],
   "source": [
    "cleaner_candidates = [\n",
    "    (NoOutlierDetection, NoImputation),\n",
    "    (NoOutlierDetection, MeanModeImputation),\n",
    "    (NoOutlierDetection, DatawigImputation),\n",
    "    (PyODKNN, NoImputation),\n",
    "    (PyODKNN, MeanModeImputation),\n",
    "    (PyODKNN, DatawigImputation),\n",
    "    (PyODIsolationForest, NoImputation),\n",
    "    (PyODIsolationForest, MeanModeImputation),\n",
    "    (PyODIsolationForest, DatawigImputation)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rzDvtkcNIxha"
   },
   "outputs": [],
   "source": [
    "cleaners = []\n",
    "for outd, imp in cleaner_candidates:\n",
    "    cleaners.append(Cleaner(train_data, \n",
    "                            test_data_corrupted, \n",
    "                            categorical_columns, \n",
    "                            numerical_columns, \n",
    "                            outlier_detection = outd(train_data, \n",
    "                                                     test_data_corrupted, \n",
    "                                                     categorical_columns, \n",
    "                                                     numerical_columns), \n",
    "                            imputation = imp(train_data, \n",
    "                                             test_data_corrupted, \n",
    "                                             categorical_columns, \n",
    "                                             numerical_columns)\n",
    "                           ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yt21AxY3Ixhv",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cleaner_scores_ppp = []\n",
    "for cleaner in cleaners:\n",
    "    test_data_cleaned = cleaner.apply_cleaner(train_data, test_data_corrupted, categorical_columns, numerical_columns)\n",
    "    cleaner_score = ppp.predict_score_ppp(ppp_model, test_data_cleaned)\n",
    "    print(f\"PPP score with {cleaner}: {cleaner_score}\")\n",
    "    cleaner_scores_ppp.append(cleaner_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KjyJVghTIxh1",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cleaner_scores_ppp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_cleaning_idx = pd.Series(cleaner_scores_ppp).idxmax()\n",
    "best_cleaning_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_cleaning_score = cleaner_scores_ppp[best_cleaning_idx]\n",
    "best_cleaning_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if best_cleaning_score > score_no_cleaning:\n",
    "    test_data_cleaned = cleaners[best_cleaning_idx].apply_cleaner(train_data, test_data_corrupted, categorical_columns, numerical_columns)\n",
    "    print(f\"Best cleaning method: {cleaners[best_cleaning_idx]}: {best_cleaning_score}\")\n",
    "else:\n",
    "    print(\"Cleaning didnt't improve the score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## using clean class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = Clean(train_data, test_data_corrupted, categorical_columns, numerical_columns, ppp, ppp_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_cleaned, score_no_cleaning, cleaner_scores_ppp = clean(train_data, test_data_corrupted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jenga.cleaning.outlier_detection import NoOutlierDetection\n",
    "from jenga.cleaning.imputation import NoImputation\n",
    "\n",
    "\n",
    "class Cleaner:\n",
    "    \n",
    "    def __init__(self, \n",
    "                 df_train,\n",
    "                 df_corrupted,\n",
    "                 categorical_columns,\n",
    "                 numerical_columns,\n",
    "                 outlier_detection=NoOutlierDetection, \n",
    "                 imputation=NoImputation):\n",
    "        self.outlier_detection = outlier_detection\n",
    "        self.imputation = imputation\n",
    "        \n",
    "    \n",
    "    def apply_cleaner(self, df_train, df_corrupted, categorical_columns, numerical_columns):\n",
    "        df_cleaned = self.outlier_detection(df_train, df_corrupted)\n",
    "        \n",
    "        # do something for fixing/removing the outliers\n",
    "        if 'outlier' in df_cleaned.columns:\n",
    "            ### TODO \n",
    "            df_cleaned = df_cleaned.drop('outlier', axis=1)\n",
    "            \n",
    "        # impute\n",
    "        df_cleaned = self.imputation(df_train, df_cleaned)\n",
    "        \n",
    "        return df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VKGKBDeiIxiS"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from jenga.cleaning.ppp import PipelinePerformancePrediction\n",
    "from jenga.cleaning.cleaner import Cleaner\n",
    "from jenga.cleaning.outlier_detection import NoOutlierDetection, PyODKNN, PyODIsolationForest\n",
    "from jenga.cleaning.imputation import NoImputation, MeanModeImputation, DatawigImputation\n",
    "\n",
    "\n",
    "DEFAULT_CLEANERS = [\n",
    "    (NoOutlierDetection, NoImputation),\n",
    "    (NoOutlierDetection, MeanModeImputation),\n",
    "    (NoOutlierDetection, DatawigImputation),\n",
    "    (PyODKNN, NoImputation),\n",
    "    (PyODKNN, MeanModeImputation),\n",
    "    (PyODKNN, DatawigImputation),\n",
    "    (PyODIsolationForest, NoImputation),\n",
    "    (PyODIsolationForest, MeanModeImputation),\n",
    "    (PyODIsolationForest, DatawigImputation)\n",
    "]\n",
    "\n",
    "\n",
    "class Clean:\n",
    "    \n",
    "    def __init__(self, \n",
    "                 df_train, \n",
    "                 df_corrupted, \n",
    "                 categorical_columns, \n",
    "                 numerical_columns,\n",
    "                 ppp,\n",
    "                 ppp_model,\n",
    "                 cleaners=DEFAULT_CLEANERS):\n",
    "\n",
    "        self.categorical_columns = categorical_columns\n",
    "        self.numerical_columns = numerical_columns\n",
    "        \n",
    "        self.ppp = ppp\n",
    "        self.ppp_model = ppp_model\n",
    "        \n",
    "        self.cleaners = []\n",
    "        for outd, imp in cleaners:\n",
    "            self.cleaners.append(Cleaner(df_train,\n",
    "                                         df_corrupted,\n",
    "                                         self.categorical_columns,\n",
    "                                         self.numerical_columns,\n",
    "                                         outlier_detection = outd(df_train,\n",
    "                                                                  df_corrupted,\n",
    "                                                                  self.categorical_columns,\n",
    "                                                                  self.numerical_columns),\n",
    "                                         imputation = imp(df_train,\n",
    "                                                          df_corrupted,\n",
    "                                                          self.categorical_columns,\n",
    "                                                          self.numerical_columns)\n",
    "                                        )\n",
    "                                )\n",
    "            \n",
    "        \n",
    "    def get_cleaned(self, df_train, df_corrupted):\n",
    "        \n",
    "        score_no_cleaning = self.ppp.predict_score_ppp(self.ppp_model, df_corrupted)\n",
    "        print(f\"PPP score no cleaning: {score_no_cleaning}\")\n",
    "        \n",
    "        cleaner_scores_ppp = []\n",
    "        for cleaner in self.cleaners:\n",
    "            df_cleaned = cleaner.apply_cleaner(df_train, df_corrupted, self.categorical_columns, self.numerical_columns)\n",
    "            cleaner_score = self.ppp.predict_score_ppp(self.ppp_model, df_cleaned)\n",
    "            print(f\"PPP score with cleaning: {cleaner}: {cleaner_score}\")\n",
    "            cleaner_scores_ppp.append(cleaner_score)\n",
    "            \n",
    "        best_cleaning_idx = pd.Series(cleaner_scores_ppp).idxmax()\n",
    "        best_cleaning_score = cleaner_scores_ppp[best_cleaning_idx]\n",
    "        if best_cleaning_score > score_no_cleaning:\n",
    "            df_cleaned = self.cleaners[best_cleaning_idx].apply_cleaner(df_train, df_corrupted, self.categorical_columns, self.numerical_columns)\n",
    "            print(f\"Best cleaning method: {self.cleaners[best_cleaning_idx]}: {best_cleaning_score}\")\n",
    "        else:\n",
    "            print(\"Cleaning didnt't improve the score\")\n",
    "            \n",
    "        return df_cleaned, score_no_cleaning, cleaner_scores_ppp\n",
    "    \n",
    "    \n",
    "    def __call__(self, df_train, df_corrupted):\n",
    "        return self.get_cleaned(df_train, df_corrupted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-bBVejn2IxiV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qX4ctIZbIxiZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EZ3-djAoIxic"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-wDqb4WJIxif"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "giUQLah_Ixii"
   },
   "source": [
    "### Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kdF9cfx8Ixik"
   },
   "outputs": [],
   "source": [
    "# detection using KNN from PyOD\n",
    "outlier = PyODKNN(train_data, test_data_corrupted, categorical_columns, numerical_columms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IAC7CVcUIxin",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_data_corrupted_outliers = outlier.fit_transform(train_data, test_data_corrupted)\n",
    "test_data_corrupted_outliers.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NK849TnbIxir"
   },
   "outputs": [],
   "source": [
    "# detection using Isolation Forest from PyOD\n",
    "outlier_if = PyODIsolationForest(train_data, test_data_corrupted, categorical_columns, numerical_columms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s8sxdokFIxiu",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_data_corrupted_outliers_if = outlier_if.fit_transform(train_data, test_data_corrupted)\n",
    "test_data_corrupted_outliers_if.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sLY3PU0mIxiz"
   },
   "source": [
    "#### Preparing the outliers for imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vKW5cQUCIxiz",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if \"outlier\" in test_data_corrupted_outliers.columns:\n",
    "    print(f'Setting {test_data_corrupted_outliers[\"outlier\"].sum()} to Nan')\n",
    "    test_data_corrupted_outliers.loc[test_data_corrupted_outliers[\"outlier\"], :] = np.nan\n",
    "    test_data_corrupted_outliers = test_data_corrupted_outliers.drop('outlier', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NyaQVtKxIxi2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jBl_oQIOIxi5"
   },
   "outputs": [],
   "source": [
    "## train_data, test_data_corrupted, \n",
    "## check values in column in the training data -> check for outliers in the same column in the corrupted data\n",
    "## store .loc \n",
    "## convert those .loc for those column into nan\n",
    "## impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ttxqXzEyIxi8"
   },
   "outputs": [],
   "source": [
    "numerical_columms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tH09weY3Ixi-"
   },
   "outputs": [],
   "source": [
    "test_data_corrupted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j52Dm8-9IxjB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-7mi-wm7IxjK"
   },
   "outputs": [],
   "source": [
    "from abc import abstractmethod\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from pyod.models.knn import KNN\n",
    "from pyod.models.iforest import IForest\n",
    "\n",
    "\n",
    "class OutlierDetection:\n",
    "    \n",
    "    def __init__(self, df_train, df_corrupted, categorical_columns, numerical_columns):\n",
    "        \n",
    "        self.df_train = df_train\n",
    "        self.df_corrupted = df_corrupted\n",
    "        \n",
    "        self.categorical_columns = categorical_columns\n",
    "        self.numerical_columns = numerical_columns\n",
    "        \n",
    "        \n",
    "        # preprocessing pipeline for numerical columns\n",
    "        transformer_numeric = Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='constant', fill_value=0)),\n",
    "            ('standard_scale', StandardScaler())\n",
    "        ])\n",
    "\n",
    "        # preprocessing pipeline for categorical columns\n",
    "        transformer_categorical = Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='constant', fill_value='__NA__')),\n",
    "            ('one_hot_encode', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ])\n",
    "\n",
    "        # preprocessor\n",
    "        self.feature_transform = ColumnTransformer(transformers=[\n",
    "            ('categorical_features', transformer_categorical, self.categorical_columns),\n",
    "            ('numerical_features', transformer_numeric, self.numerical_columns)\n",
    "        ], sparse_threshold=1.0)\n",
    "        \n",
    "        \n",
    "        @abstractmethod\n",
    "        def fit_transform(self, df_train, df_corrupted):\n",
    "            pass\n",
    "\n",
    "\n",
    "\n",
    "class NoOutlierDetection(OutlierDetection):\n",
    "    \n",
    "    def fit_transform(self, df_train, df_corrupted):\n",
    "        df_outliers = df_corrupted.copy()\n",
    "        \n",
    "        return df_outliers\n",
    "    \n",
    "    \n",
    "    def __call__(self, df_train, df_corrupted):\n",
    "        return self.fit_transform(df_train, df_corrupted)\n",
    "\n",
    "\n",
    "        \n",
    "class PyODKNN(OutlierDetection):\n",
    "    \n",
    "    def fit_transform(self, df_train, df_corrupted):\n",
    "        df_outliers = df_corrupted.copy()\n",
    "        \n",
    "        feature_transformation = self.feature_transform.fit(df_train)\n",
    "        x = feature_transformation.transform(df_train).toarray()\n",
    "        \n",
    "        model = KNN()\n",
    "        model.fit(x)\n",
    "        \n",
    "        xx = feature_transformation.transform(df_outliers).toarray()\n",
    "\n",
    "        df_outliers[\"outlier\"] = model.predict(xx) ## 0: inlier, 1: outlier\n",
    "        \n",
    "        return df_outliers\n",
    "    \n",
    "    \n",
    "    def __call__(self, df_train, df_corrupted):\n",
    "        return self.fit_transform(df_train, df_corrupted)\n",
    "\n",
    "    \n",
    "    \n",
    "class PyODIsolationForest(OutlierDetection):\n",
    "    \n",
    "    def fit_transform(self, df_train, df_corrupted):\n",
    "        df_outliers = df_corrupted.copy()\n",
    "        \n",
    "        feature_transformation = self.feature_transform.fit(df_train)\n",
    "        x = feature_transformation.transform(df_train).toarray()\n",
    "        \n",
    "        model = IForest(contamination=0.25)\n",
    "        model.fit(x)\n",
    "        \n",
    "        xx = feature_transformation.transform(df_outliers).toarray()\n",
    "\n",
    "        df_outliers[\"outlier\"] = model.predict(xx) ## 0: inlier, 1: outlier\n",
    "        \n",
    "        return df_outliers\n",
    "    \n",
    "    \n",
    "    def __call__(self, df_train, df_corrupted):\n",
    "        return self.fit_transform(df_train, df_corrupted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "05f9KFx7IxjN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u69nHssRIxjQ"
   },
   "outputs": [],
   "source": [
    "from abc import abstractmethod\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import datawig\n",
    "\n",
    "\n",
    "\n",
    "class Imputation:\n",
    "    \n",
    "    def __init__(self, df_train, df_corrupted, categorical_columns, numerical_columns):\n",
    "        self.df_train = df_train\n",
    "        self.df_corrupted = df_corrupted\n",
    "        \n",
    "        self.categorical_columns = categorical_columns\n",
    "        self.numerical_columns = numerical_columns\n",
    "        \n",
    "    \n",
    "    @abstractmethod\n",
    "    def fit_transform(self, df_train, df_corrupted):\n",
    "        pass\n",
    "\n",
    "    \n",
    "    \n",
    "class NoImputation(Imputation):    \n",
    "    \n",
    "    def __init__(self, df_train, df_corrupted, categorical_columns, numerical_columns):        \n",
    "        Imputation.__init__(self, df_train, df_corrupted, categorical_columns, numerical_columns)\n",
    "    \n",
    "    \n",
    "    def fit_transform(self, df_train, df_corrupted):\n",
    "        df_imputed = df_corrupted.copy()\n",
    "        return df_imputed\n",
    "    \n",
    "    \n",
    "    def __call__(self, df_train, df_corrupted):\n",
    "        return self.fit_transform(df_train, df_corrupted)\n",
    "    \n",
    "    \n",
    "    \n",
    "class MeanModeImputation(Imputation):\n",
    "    \n",
    "    def __init__(self, df_train, df_corrupted, categorical_columns, numerical_columns):\n",
    "        self.means = {}\n",
    "        self.modes = {}\n",
    "    \n",
    "        Imputation.__init__(self, df_train, df_corrupted, categorical_columns, numerical_columns)\n",
    "    \n",
    "    \n",
    "    def fit_transform(self, df_train, df_corrupted):\n",
    "        df_imputed = df_corrupted.copy()\n",
    "        \n",
    "        for col in df_train.columns:\n",
    "            if col in self.numerical_columns:\n",
    "                # mean imputer\n",
    "                mean = np.mean(df_train[col])\n",
    "                self.means[col] = mean\n",
    "            elif col in self.categorical_columns:\n",
    "                # mode imputer\n",
    "                mode = df_train[col].value_counts().index[0]\n",
    "                self.modes[col] = mode\n",
    "                \n",
    "                \n",
    "        for col in df_corrupted.columns:\n",
    "            if col in self.numerical_columns:\n",
    "                # mean imputer\n",
    "                df_imputed[col].fillna(self.means[col], inplace=True)\n",
    "            elif col in self.categorical_columns:\n",
    "                # mode imputer\n",
    "                df_imputed[col].fillna(self.modes[col], inplace=True)\n",
    "                \n",
    "        return df_imputed\n",
    "    \n",
    "    \n",
    "    def __call__(self, df_train, df_corrupted):\n",
    "        return self.fit_transform(df_train, df_corrupted)\n",
    "\n",
    "    \n",
    "\n",
    "class DatawigImputation(Imputation):\n",
    "    \n",
    "    def __init__(self, df_train, df_corrupted, categorical_columns, numerical_columns):        \n",
    "        Imputation.__init__(self, df_train, df_corrupted, categorical_columns, numerical_columns)\n",
    "    \n",
    "    \n",
    "    def fit_transform(self, df_train, df_corrupted):\n",
    "        df_imputed = df_corrupted.copy()\n",
    "\n",
    "        for col in df_train.columns:\n",
    "            if pd.api.types.is_categorical_dtype(df_train[col]):\n",
    "                df_train[col] = df_train[col].astype(str)\n",
    "\n",
    "        for col in df_corrupted.columns:\n",
    "            if pd.api.types.is_categorical_dtype(df_corrupted[col]):\n",
    "                df_corrupted[col] = df_corrupted[col].astype(str)\n",
    "\n",
    "\n",
    "        for col in self.categorical_columns + self.numerical_columns:\n",
    "            output_column = col\n",
    "            input_columns = list(set(df_train.columns) - set([output_column]))\n",
    "\n",
    "            print(f\"Fitting model for column: {col}\")\n",
    "            model = datawig.SimpleImputer(input_columns, output_column, 'imputer_model')\n",
    "            model.fit(df_train)\n",
    "\n",
    "            df_imputed = model.predict(df_imputed)\n",
    "            df_imputed[col].fillna(df_imputed[col + '_imputed'], inplace=True)\n",
    "            df_imputed = df_imputed[df_corrupted.columns]\n",
    "\n",
    "        return df_imputed\n",
    "    \n",
    "    \n",
    "    def __call__(self, df_train, df_corrupted):\n",
    "        return self.fit_transform(df_train, df_corrupted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kjEBP-v3IxjT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LynEGFxXIxjU"
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X4-165s0IxjV"
   },
   "outputs": [],
   "source": [
    "# score without cleaning\n",
    "model_obj.score_on_test_data(model.predict_proba(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VeCnv0oDIxjY"
   },
   "outputs": [],
   "source": [
    "# score with corruptions\n",
    "model_obj.score_on_test_data(model.predict_proba(test_data_corrupted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j0NNNNLAIxjc"
   },
   "outputs": [],
   "source": [
    "# score with mean/mode imputation\n",
    "model_obj.score_on_test_data(model.predict_proba(test_data_mm_imputed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Woo7_55yIxje"
   },
   "outputs": [],
   "source": [
    "# score with datawig imputation\n",
    "model_obj.score_on_test_data(model.predict_proba(test_data_dw_imputed))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "gLZUJSdkIxf0",
    "giUQLah_Ixii",
    "sLY3PU0mIxiz"
   ],
   "name": "experimental_setup_refined_classes.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
